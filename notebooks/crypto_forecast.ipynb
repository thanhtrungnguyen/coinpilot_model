{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-15T17:48:31.658796Z",
     "start_time": "2025-04-15T17:48:31.654485Z"
    }
   },
   "source": [
    "# multi_crypto_forecast.py\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv1D, LSTM, RepeatVector, TimeDistributed, Dense, Dropout, LayerNormalization, Bidirectional\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import mlflow.tensorflow\n",
    "import yfinance as yf\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T17:48:31.675061Z",
     "start_time": "2025-04-15T17:48:31.671223Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "mlflow.tensorflow.autolog()"
   ],
   "id": "48ab879359ec0777",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/16 00:48:31 WARNING mlflow.utils.autologging_utils: MLflow tensorflow autologging is known to be compatible with 2.7.4 <= tensorflow <= 2.18.0, but the installed version is 2.19.0. If you encounter errors during autologging, try upgrading / downgrading tensorflow to a compatible version, or try upgrading MLflow.\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T17:48:31.705790Z",
     "start_time": "2025-04-15T17:48:31.694937Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# --- Parameters ---\n",
    "WINDOW_SIZE = 30\n",
    "FORECAST_HORIZON = 5\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 100\n",
    "CRYPTO_SYMBOLS = [\"BTC-USD\", \"ETH-USD\", \"DOGE-USD\", \"LTC-USD\"]\n",
    "EXTERNAL_SYMBOLS = [\"GLD\", \"CL=F\", \"^GSPC\"]  # Gold, Oil, S&P 500\n",
    "START_DATE = \"2018-01-01\"\n",
    "END_DATE = \"2024-01-01\"\n",
    "MODEL_DIR = \"../models/model.keras\"\n",
    "\n",
    "# --- Download and prepare dataset ---\n",
    "def fetch_market_data(symbols, start, end):\n",
    "    dfs = []\n",
    "    for sym in symbols:\n",
    "        data = yf.download(sym, start=start, end=end)[['Close']]\n",
    "        data.columns = [sym]\n",
    "        dfs.append(data)\n",
    "    df = pd.concat(dfs, axis=1).dropna()\n",
    "    return df\n",
    "\n",
    "def fetch_sentiment_data():\n",
    "    # Placeholder for real sentiment ingestion (Twitter, Reddit, etc.)\n",
    "    # In practice, replace this with actual sentiment feature generation\n",
    "    # Here we simulate 3 sentiment scores for BTC, ETH, DOGE over time\n",
    "    dates = pd.date_range(start=START_DATE, end=END_DATE, freq='D')\n",
    "    np.random.seed(42)\n",
    "    sentiment = pd.DataFrame({\n",
    "        'Date': dates,\n",
    "        'BTC_sentiment': np.random.uniform(-1, 1, len(dates)),\n",
    "        'ETH_sentiment': np.random.uniform(-1, 1, len(dates)),\n",
    "        'DOGE_sentiment': np.random.uniform(-1, 1, len(dates))\n",
    "    })\n",
    "    sentiment = sentiment.set_index('Date')\n",
    "    return sentiment\n",
    "\n",
    "def load_data():\n",
    "    price_df = fetch_market_data(CRYPTO_SYMBOLS, START_DATE, END_DATE)\n",
    "    external_df = fetch_market_data(EXTERNAL_SYMBOLS, START_DATE, END_DATE)\n",
    "    sentiment_df = fetch_sentiment_data()\n",
    "\n",
    "    df = price_df.join(external_df, how='inner')\n",
    "    df = df.join(sentiment_df, how='inner')\n",
    "    df = df.reset_index().sort_values('Date')\n",
    "    df = df.drop(columns=['Date'])\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled = scaler.fit_transform(df)\n",
    "    return scaled, scaler, df.columns.tolist()\n",
    "\n",
    "def create_sequences(data, window_size, forecast_horizon):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - window_size - forecast_horizon):\n",
    "        X.append(data[i:i + window_size])\n",
    "        y.append(data[i + window_size:i + window_size + forecast_horizon])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# --- Build Conv-BiLSTM Encoder-Decoder Model ---\n",
    "def build_model(input_shape, output_steps):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = Conv1D(filters=64, kernel_size=3, activation='relu', padding='causal')(inputs)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = LayerNormalization()(x)\n",
    "    x = Bidirectional(LSTM(100, return_sequences=False))(x)\n",
    "    x = RepeatVector(output_steps)(x)\n",
    "    x = LSTM(100, return_sequences=True)(x)\n",
    "    outputs = TimeDistributed(Dense(input_shape[1]))(x)\n",
    "    model = Model(inputs, outputs)\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "# --- Plotting helper ---\n",
    "def log_predictions(X_val, y_val, y_pred, feature_names):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i in range(min(len(feature_names), 6)):  # Plot top 6 features max\n",
    "        plt.plot(y_val[0, :, i], label=f\"True - {feature_names[i]}\", linestyle='--')\n",
    "        plt.plot(y_pred[0, :, i], label=f\"Pred - {feature_names[i]}\")\n",
    "    plt.title(\"Sample Forecast vs Actual\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    os.makedirs(\"plots\", exist_ok=True)\n",
    "    plt.savefig(\"plots/sample_forecast.png\")\n",
    "    mlflow.log_artifact(\"plots/sample_forecast.png\")\n",
    "    plt.close()\n",
    "\n",
    "# --- Training Pipeline ---\n",
    "def train_model():\n",
    "    data, scaler, feature_names = load_data()\n",
    "    NUM_FEATURES = data.shape[1]\n",
    "    X, y = create_sequences(data, WINDOW_SIZE, FORECAST_HORIZON)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "    model = build_model((WINDOW_SIZE, NUM_FEATURES), FORECAST_HORIZON)\n",
    "\n",
    "    with mlflow.start_run():\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_val, y_val),\n",
    "            epochs=EPOCHS,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            callbacks=[\n",
    "                tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True),\n",
    "                tf.keras.callbacks.ReduceLROnPlateau(patience=5, factor=0.5)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        model.save(MODEL_DIR, save_format='keras')\n",
    "        mlflow.log_artifact(MODEL_DIR)\n",
    "\n",
    "        # Evaluate and log predictions\n",
    "        y_pred = model.predict(X_val[:1])\n",
    "        print(X_val, y_val, y_pred, feature_names)\n",
    "        log_predictions(X_val, y_val, y_pred, feature_names)"
   ],
   "id": "e73035eb9666b199",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T17:48:56.048716Z",
     "start_time": "2025-04-15T17:48:31.721673Z"
    }
   },
   "cell_type": "code",
   "source": "train_model()",
   "id": "a8c5209bcb7f7b34",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/plain": [],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001B[1m18/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 0.1072 - mae: 0.2405"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 49ms/step - loss: 0.1032 - mae: 0.2352 - val_loss: 0.0394 - val_mae: 0.1427 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 0.0368 - mae: 0.1349"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 29ms/step - loss: 0.0367 - mae: 0.1346 - val_loss: 0.0289 - val_mae: 0.1144 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 27ms/step - loss: 0.0297 - mae: 0.1145 - val_loss: 0.0296 - val_mae: 0.1199 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 27ms/step - loss: 0.0282 - mae: 0.1081 - val_loss: 0.0297 - val_mae: 0.1186 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 27ms/step - loss: 0.0276 - mae: 0.1057 - val_loss: 0.0292 - val_mae: 0.1162 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001B[1m18/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 0.0271 - mae: 0.1037"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 30ms/step - loss: 0.0272 - mae: 0.1036 - val_loss: 0.0285 - val_mae: 0.1135 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 28ms/step - loss: 0.0273 - mae: 0.1020 - val_loss: 0.0294 - val_mae: 0.1188 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 28ms/step - loss: 0.0269 - mae: 0.1000 - val_loss: 0.0287 - val_mae: 0.1138 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 0.0268 - mae: 0.1000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 31ms/step - loss: 0.0268 - mae: 0.1000 - val_loss: 0.0284 - val_mae: 0.1137 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 27ms/step - loss: 0.0265 - mae: 0.0985 - val_loss: 0.0284 - val_mae: 0.1140 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 28ms/step - loss: 0.0265 - mae: 0.0984 - val_loss: 0.0294 - val_mae: 0.1187 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001B[1m18/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━━\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 0.0263 - mae: 0.0973"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 32ms/step - loss: 0.0263 - mae: 0.0973 - val_loss: 0.0282 - val_mae: 0.1123 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 26ms/step - loss: 0.0260 - mae: 0.0964 - val_loss: 0.0284 - val_mae: 0.1142 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 29ms/step - loss: 0.0259 - mae: 0.0956 - val_loss: 0.0288 - val_mae: 0.1158 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 28ms/step - loss: 0.0258 - mae: 0.0951 - val_loss: 0.0288 - val_mae: 0.1148 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 28ms/step - loss: 0.0256 - mae: 0.0949 - val_loss: 0.0289 - val_mae: 0.1158 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 28ms/step - loss: 0.0256 - mae: 0.0948 - val_loss: 0.0284 - val_mae: 0.1124 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 29ms/step - loss: 0.0253 - mae: 0.0926 - val_loss: 0.0286 - val_mae: 0.1152 - learning_rate: 5.0000e-04\n",
      "Epoch 19/100\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 28ms/step - loss: 0.0251 - mae: 0.0917 - val_loss: 0.0283 - val_mae: 0.1138 - learning_rate: 5.0000e-04\n",
      "Epoch 20/100\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 29ms/step - loss: 0.0253 - mae: 0.0920 - val_loss: 0.0285 - val_mae: 0.1151 - learning_rate: 5.0000e-04\n",
      "Epoch 21/100\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 27ms/step - loss: 0.0249 - mae: 0.0913 - val_loss: 0.0290 - val_mae: 0.1165 - learning_rate: 5.0000e-04\n",
      "Epoch 22/100\n",
      "\u001B[1m19/19\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 28ms/step - loss: 0.0249 - mae: 0.0908 - val_loss: 0.0289 - val_mae: 0.1166 - learning_rate: 5.0000e-04\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 322ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=keras\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 334ms/step\n",
      "[[[0.25009737 0.32806934 0.08699725 ... 0.05835337 0.25127169 0.74224157]\n",
      "  [0.2819876  0.3457812  0.0914481  ... 0.78051281 0.84458407 0.05174001]\n",
      "  [0.29736743 0.3446559  0.09128271 ... 0.99543522 0.30859673 0.87479496]\n",
      "  ...\n",
      "  [0.2535319  0.26384594 0.08547216 ... 0.53412396 0.08415423 0.01745092]\n",
      "  [0.2501686  0.25934772 0.08523945 ... 0.21279319 0.39327079 0.10185007]\n",
      "  [0.24713894 0.25412269 0.08368362 ... 0.00893651 0.10027945 0.41036747]]\n",
      "\n",
      " [[0.2819876  0.3457812  0.0914481  ... 0.78051281 0.84458407 0.05174001]\n",
      "  [0.29736743 0.3446559  0.09128271 ... 0.99543522 0.30859673 0.87479496]\n",
      "  [0.26512859 0.3165291  0.0857561  ... 0.05477067 0.5732908  0.35233199]\n",
      "  ...\n",
      "  [0.2501686  0.25934772 0.08523945 ... 0.21279319 0.39327079 0.10185007]\n",
      "  [0.24713894 0.25412269 0.08368362 ... 0.00893651 0.10027945 0.41036747]\n",
      "  [0.24580516 0.25358474 0.08488818 ... 0.23889207 0.01658838 0.93365679]]\n",
      "\n",
      " [[0.29736743 0.3446559  0.09128271 ... 0.99543522 0.30859673 0.87479496]\n",
      "  [0.26512859 0.3165291  0.0857561  ... 0.05477067 0.5732908  0.35233199]\n",
      "  [0.26426395 0.32794398 0.08728411 ... 0.69445906 0.32534725 0.72290777]\n",
      "  ...\n",
      "  [0.24713894 0.25412269 0.08368362 ... 0.00893651 0.10027945 0.41036747]\n",
      "  [0.24580516 0.25358474 0.08488818 ... 0.23889207 0.01658838 0.93365679]\n",
      "  [0.24765094 0.25712667 0.08459253 ... 0.97637013 0.66200755 0.63752958]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.4942901  0.3840131  0.10954276 ... 0.89042745 0.98295583 0.15527124]\n",
      "  [0.50060484 0.38153559 0.10535244 ... 0.07647929 0.08615961 0.22532289]\n",
      "  [0.50389621 0.38178901 0.10822551 ... 0.73105957 0.81474498 0.21144067]\n",
      "  ...\n",
      "  [0.61845152 0.47216055 0.14155787 ... 0.85577482 0.66681303 0.05239759]\n",
      "  [0.60144062 0.4515924  0.13387243 ... 0.22481662 0.08013047 0.75519345]\n",
      "  [0.61222629 0.45115584 0.13245565 ... 0.64210657 0.18453118 0.32329434]]\n",
      "\n",
      " [[0.50060484 0.38153559 0.10535244 ... 0.07647929 0.08615961 0.22532289]\n",
      "  [0.50389621 0.38178901 0.10822551 ... 0.73105957 0.81474498 0.21144067]\n",
      "  [0.52003081 0.43069964 0.10526901 ... 0.18489713 0.28045042 0.7928435 ]\n",
      "  ...\n",
      "  [0.60144062 0.4515924  0.13387243 ... 0.22481662 0.08013047 0.75519345]\n",
      "  [0.61222629 0.45115584 0.13245565 ... 0.64210657 0.18453118 0.32329434]\n",
      "  [0.6067383  0.44282193 0.12991042 ... 0.69357103 0.20237418 0.18342355]]\n",
      "\n",
      " [[0.50389621 0.38178901 0.10822551 ... 0.73105957 0.81474498 0.21144067]\n",
      "  [0.52003081 0.43069964 0.10526901 ... 0.18489713 0.28045042 0.7928435 ]\n",
      "  [0.52968258 0.4217586  0.10817135 ... 0.85822393 0.13222805 0.18652148]\n",
      "  ...\n",
      "  [0.61222629 0.45115584 0.13245565 ... 0.64210657 0.18453118 0.32329434]\n",
      "  [0.6067383  0.44282193 0.12991042 ... 0.69357103 0.20237418 0.18342355]\n",
      "  [0.62821885 0.44790652 0.13154967 ... 0.51138206 0.38687104 0.57699438]]] [[[0.24580516 0.25358474 0.08488818 ... 0.23889207 0.01658838 0.93365679]\n",
      "  [0.24765094 0.25712667 0.08459253 ... 0.97637013 0.66200755 0.63752958]\n",
      "  [0.25034204 0.26665591 0.08484427 ... 0.48648664 0.23390738 0.36147924]\n",
      "  [0.26200613 0.2913328  0.08978543 ... 0.10692473 0.02370688 0.10792517]\n",
      "  [0.27249336 0.31352107 0.10430156 ... 0.54682163 0.83531475 0.8763317 ]]\n",
      "\n",
      " [[0.24765094 0.25712667 0.08459253 ... 0.97637013 0.66200755 0.63752958]\n",
      "  [0.25034204 0.26665591 0.08484427 ... 0.48648664 0.23390738 0.36147924]\n",
      "  [0.26200613 0.2913328  0.08978543 ... 0.10692473 0.02370688 0.10792517]\n",
      "  [0.27249336 0.31352107 0.10430156 ... 0.54682163 0.83531475 0.8763317 ]\n",
      "  [0.26495958 0.30248168 0.11047509 ... 0.45288208 0.9751216  0.78345308]]\n",
      "\n",
      " [[0.25034204 0.26665591 0.08484427 ... 0.48648664 0.23390738 0.36147924]\n",
      "  [0.26200613 0.2913328  0.08978543 ... 0.10692473 0.02370688 0.10792517]\n",
      "  [0.27249336 0.31352107 0.10430156 ... 0.54682163 0.83531475 0.8763317 ]\n",
      "  [0.26495958 0.30248168 0.11047509 ... 0.45288208 0.9751216  0.78345308]\n",
      "  [0.26977138 0.31117562 0.12054329 ... 0.84435119 0.13550941 0.16771089]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.6067383  0.44282193 0.12991042 ... 0.69357103 0.20237418 0.18342355]\n",
      "  [0.62821885 0.44790652 0.13154967 ... 0.51138206 0.38687104 0.57699438]\n",
      "  [0.63159086 0.45586609 0.13679966 ... 0.30324612 0.05116179 0.15441907]\n",
      "  [0.63359244 0.47426425 0.13708359 ... 0.21022593 0.39796245 0.35600087]\n",
      "  [0.61062291 0.45415765 0.13146039 ... 0.93865771 0.83951606 0.42012946]]\n",
      "\n",
      " [[0.62821885 0.44790652 0.13154967 ... 0.51138206 0.38687104 0.57699438]\n",
      "  [0.63159086 0.45586609 0.13679966 ... 0.30324612 0.05116179 0.15441907]\n",
      "  [0.63359244 0.47426425 0.13708359 ... 0.21022593 0.39796245 0.35600087]\n",
      "  [0.61062291 0.45415765 0.13146039 ... 0.93865771 0.83951606 0.42012946]\n",
      "  [0.62496356 0.48530857 0.13471401 ... 0.87130112 0.14538105 0.56215226]]\n",
      "\n",
      " [[0.63159086 0.45586609 0.13679966 ... 0.30324612 0.05116179 0.15441907]\n",
      "  [0.63359244 0.47426425 0.13708359 ... 0.21022593 0.39796245 0.35600087]\n",
      "  [0.61062291 0.45415765 0.13146039 ... 0.93865771 0.83951606 0.42012946]\n",
      "  [0.62496356 0.48530857 0.13471401 ... 0.87130112 0.14538105 0.56215226]\n",
      "  [0.6122934  0.47871481 0.13223318 ... 0.76575988 0.50591476 0.00527279]]] [[[0.2653076  0.3065295  0.11370482 0.08815812 0.6268514  0.84217507\n",
      "   0.6633986  0.471839   0.49734342 0.5104188 ]\n",
      "  [0.24884798 0.28359303 0.10798573 0.06824761 0.60348374 0.8220512\n",
      "   0.6458172  0.44711053 0.49586973 0.49035963]\n",
      "  [0.25715628 0.28275308 0.10951468 0.07117366 0.6101957  0.83753955\n",
      "   0.654576   0.46004468 0.50435084 0.49656457]\n",
      "  [0.2600385  0.27752894 0.10798816 0.07105655 0.605512   0.83522767\n",
      "   0.65168625 0.46050012 0.50176114 0.4940024 ]\n",
      "  [0.26222926 0.27514383 0.10723829 0.07104669 0.60375905 0.8352765\n",
      "   0.6509172  0.460791   0.50057614 0.49331495]]] ['BTC-USD', 'ETH-USD', 'DOGE-USD', 'LTC-USD', 'GLD', 'CL=F', '^GSPC', 'BTC_sentiment', 'ETH_sentiment', 'DOGE_sentiment']\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T17:48:56.059908Z",
     "start_time": "2025-04-15T17:48:56.058298Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "acc24e5c3fe902cc",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
